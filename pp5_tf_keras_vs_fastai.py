# -*- coding: utf-8 -*-
"""PP5 TF keras vs FASTai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dYddICxGmBifFR6_5W7rxtOKkwWDCHc9

**Užduotis**  Išmokykite ir derinkite gilųjį neuroninį tinklą naudojant dvi sistemasTF/keras ir fast.ai naudojant daugiamatės polinominės regresijos duomenu rinkini.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. Generating synthetic data for polynomial regression
def generate_polynomial_data(n_samples=1000, noise=0.1):
    np.random.seed(42)
    X = np.random.uniform(-3, 3, size=(n_samples, 2))  # Two input features
    y = (
        5 * X[:, 0] ** 3 + 2 * X[:, 1] ** 2 - 3 * X[:, 0] * X[:, 1] + noise * np.random.randn(n_samples)
    )
    return X, y

X, y = generate_polynomial_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2. TensorFlow/Keras model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Build the model
model_tf = Sequential([
    Dense(64, activation="relu", input_dim=2),
    Dense(64, activation="relu"),
    Dense(1)  # Single output
])

model_tf.compile(optimizer=Adam(learning_rate=0.01), loss="mse", metrics=["mae"])

# Train the model
history_tf = model_tf.fit(
    X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=0
)

# Evaluate the model
loss_tf, mae_tf = model_tf.evaluate(X_test, y_test, verbose=0)
print(f"TensorFlow/Keras Model - Loss: {loss_tf:.4f}, MAE: {mae_tf:.4f}")

# 3. fast.ai model
from fastai.tabular.all import *

data = np.column_stack([X, y])
df = pd.DataFrame(data, columns=["feature1", "feature2", "target"])

dls = TabularDataLoaders.from_df(df, path=".", y_names="target", cont_names=["feature1", "feature2"],
                                 valid_idx=range(len(X_train), len(X)))

learn = tabular_learner(dls, layers=[64, 64], metrics=mae)

learn.fit_one_cycle(10, lr_max=1e-2)

# Evaluate the model
fastai_preds, fastai_loss = learn.get_preds()
print(f"fast.ai Model - Losses: {[f'{x.item():.4f}' for x in fastai_loss]}")


# 4. Visualization
plt.figure(figsize=(12, 6))

# TensorFlow/Keras results
plt.subplot(1, 2, 1)
plt.scatter(y_test, model_tf.predict(X_test).flatten(), alpha=0.5, label="Predicted")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", label="Ideal")
plt.title("TensorFlow/Keras Predictions")
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.legend()

# fast.ai results
plt.subplot(1, 2, 2)
#preds_np = fastai_preds[0].numpy() # This line was selecting only the first row
preds_np = fastai_preds.numpy().flatten() # Select all predictions and flatten to 1D
plt.scatter(y_test, preds_np[:len(y_test)], alpha=0.5, label="Predicted")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", label="Ideal")
plt.title("fast.ai Predictions")
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.legend()

plt.tight_layout()
plt.show()

"""Pagal atliktą palyginimą pasirinkčiau Tensorflow keras modeklį. Šio modelio numatomos reikšmės daug arčiau prie tikrųjų reikšmių.
TensorFlow/Keras suteikia daugiau lankstumo kuriant ir pritaikant modelius, todėl jis tinka sudėtingesniems ir labiau individualizuotiems projektams.
TF/Keras geriau integruojasi su kitais įrankiais.
ensorFlow palaiko daugiau platformų ir aparatūros, pvz., GPU, TPU, mobiliosios platformos ir debesų kompiuterijos paslaugos.
Keras API leidžia visiškai kontroliuoti hiperparametrų nustatymą, optimizatorių konfigūraciją ir sluoksnių architektūrą, kas suteikia daugiau galimybių modelio optimizavimui.
"""

